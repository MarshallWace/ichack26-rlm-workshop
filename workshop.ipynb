{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marshall Wace x ICHack 2026 - Build Your Own LLM Coding Agent Using Recursive Language Models Workshop\n",
    "\n",
    "In this workshop, you'll implement the core agent loop of an RLM - a language model that can programmatically explore and analyze codebases.\n",
    "\n",
    "- [RLM Paper](https://arxiv.org/abs/2512.24601)\n",
    "- [RLM Blog Post](https://alexzhang13.github.io/blog/2025/rlm/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Recursive Language Models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### The Problem: Context Rot\n",
    "\n",
    "Modern language models have limited context windows, and even within these limits, they exhibit **context rot** - performance degrades as context gets longer. This becomes critical for long-horizon tasks that require processing millions of tokens.\n",
    "\n",
    "Traditional approaches:\n",
    "- **Context compaction** (summarizing) loses information\n",
    "- **RAG** works for needle-in-haystack but struggles when answers depend on many parts of the prompt\n",
    "\n",
    "### The Solution: Treat Prompts as Environment\n",
    "\n",
    "Instead of feeding long prompts, for example those containing entire codebases or documents, into the neural network as-is, RLMs treat the prompt as part of an **external environment** that the LLM can programmatically interact with and explore.\n",
    "\n",
    "The RLM exposes the same interface as an LLM (string in, string out), but internally:\n",
    "\n",
    "1. Loads the prompt as a variable in a REPL environment (an interactive **R**ead-**E**valuate-**P**rint-**L**oop system common in many programming languages)\n",
    "2. Lets the LLM write code to peek into, decompose, and search the prompt\n",
    "3. Allows the LLM to recursively call itself on smaller chunks\n",
    "4. Observes execution results and iterates until it finds an answer\n",
    "\n",
    "This enables handling inputs **orders of magnitude beyond model context windows**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Understanding the task and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you will put together the main components of an RLM inference framework to create your very own code analysis agent! You will then use your completed implementation to compete against others to see who can find the secret codes in a large, noisy repository first!\n",
    "\n",
    "Section 2 contains the code for the main components of the framework as well as an explanation of what you need to know and how they work.\n",
    "\n",
    "Section 3 contains the actual task and guidance on what components may be useful.\n",
    "\n",
    "You can approach the task in whatever way you prefer - the details in section 2 are included to give you a self-contained solution to take home.\n",
    "\n",
    "Good luck and please reach out to a volunteer if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important disclaimer**: This example solution allows an LLM to execute arbitrary code - **you must** run the notebook in a sandboxed environment such as Google Colab and read all code the LLM requests to run closely.\n",
    "\n",
    "Furthermore, do not include any sensitive information or confidential code in the isolated environment. The environment may help protect your host machine but it does not protect against leaking data out.\n",
    "\n",
    "You have **full control** over the implementation - **you must not** disable any safety checks in our helper functions, such as the ability to review the code before execution.\n",
    "\n",
    "Please talk to one of the volunteers if you have any questions on the specific implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to gain access to your AI tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies, imports and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "try:\n",
    "    import google.colab\n",
    "    !pip install -q litellm rich python-dotenv\n",
    "except ImportError:\n",
    "    print(\"Not in a Google Colab environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "from contextlib import contextmanager\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict, Any\n",
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Ensure your Google Gemini API key is properly set up.\n",
    "\n",
    "If running in Google Colab, create a secret by clicking on the secret tab/key icon on the left hand side of the screen, selecting \"Add new secret\", calling the secret \"ICHACK_GEMINI_KEY\" and pasting the API Key in the value field.\n",
    "The cell below will create an environment variable for you called \"GEMINI_API_KEY\" that litellm will automatically pick up.\n",
    "\n",
    "If running in another sandbox environment ensure that there is an environment variabled called \"GEMINI_API_KEY\" defined with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECRET_NAME = \"ICHACK_GEMINI_KEY\"\n",
    "GEMINI_ENV_VAR = \"GEMINI_API_KEY\"\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[GEMINI_ENV_VAR] = userdata.get(SECRET_NAME)\n",
    "except ImportError:\n",
    "    print(\"Not in a Colab environment\")\n",
    "\n",
    "if \"GEMINI_API_KEY\" not in os.environ:\n",
    "    raise EnvironmentError(\n",
    "        \"GEMINI_API_KEY not found. Set it as an environment variable.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class REPLResult:\n",
    "    stdout: str\n",
    "    stderr: str\n",
    "    locals: dict\n",
    "    execution_time: float\n",
    "\n",
    "    def __init__(self, stdout: str, stderr: str, locals: dict, execution_time: float=None):\n",
    "        self.stdout = stdout\n",
    "        self.stderr = stderr\n",
    "        self.locals = locals\n",
    "        self.execution_time = execution_time\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"REPLResult(stdout={self.stdout}, stderr={self.stderr}, locals={self.locals}, execution_time={self.execution_time})\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Iteration:\n",
    "    response: str\n",
    "    code_blocks: list[str]\n",
    "    results: list[REPLResult]\n",
    "    final_answer: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Understanding the Core Components\n",
    "\n",
    "Before implementing the RLM, let's understand the helper modules provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.1 Utilities\n",
    "This subsection defines functions that simplify the definitions of our core components. It is recommended to prioritise understanding the core components and completing the task to studying these implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_quotes_and_whitespace(s: str) -> str:\n",
    "    return s.strip().strip('\"').strip(\"'\").strip('\\n').strip('\\r')\n",
    "\n",
    "\n",
    "def _extract_balanced_parens(text: str, start_pos: int) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extract content from balanced parentheses starting at start_pos.\n",
    "\n",
    "    Args:\n",
    "        text: The full text\n",
    "        start_pos: Position of the opening '('\n",
    "\n",
    "    Returns:\n",
    "        Content between balanced parentheses, or None if not found\n",
    "    \"\"\"\n",
    "    if start_pos >= len(text) or text[start_pos] != \"(\":\n",
    "        return None\n",
    "\n",
    "    depth = 0\n",
    "    for i in range(start_pos, len(text)):\n",
    "        if text[i] == \"(\":\n",
    "            depth += 1\n",
    "        elif text[i] == \")\":\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                return text[start_pos + 1 : i].strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "def strip_code_blocks(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove all code blocks from text, leaving only the prose/explanation.\n",
    "\n",
    "    Example:\n",
    "    >>> strip_code_blocks(\"I'll check the files:\\\\n```repl\\\\nos.listdir()\\\\n```\\\\nDone!\")\n",
    "    \"I'll check the files:\\\\n\\\\nDone!\"\n",
    "    \"\"\"\n",
    "    pattern = r'```\\w*\\s*\\n.*?\\n```'\n",
    "    result = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    # Clean up multiple blank lines\n",
    "    result = re.sub(r'\\n{3,}', '\\n\\n', result)\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.syntax import Syntax\n",
    "from rich.panel import Panel\n",
    "from rich.text import Text\n",
    "from rich import box\n",
    "from rich.rule import Rule\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class CodeExecution:\n",
    "    code: str\n",
    "    stdout: str\n",
    "    stderr: str\n",
    "    execution_number: int\n",
    "    execution_time: Optional[float] = None\n",
    "\n",
    "class REPLEnvLogger:\n",
    "    def __init__(self, max_output_length: int = 2000, enabled: bool = True):\n",
    "        self.enabled = enabled\n",
    "        self.console = Console()\n",
    "        self.executions: List[CodeExecution] = []\n",
    "        self.execution_count = 0\n",
    "        self.max_output_length = max_output_length\n",
    "    \n",
    "    def _truncate_output(self, text: str) -> str:\n",
    "        \"\"\"Truncate text output to prevent overwhelming console output.\"\"\"\n",
    "        if len(text) <= self.max_output_length:\n",
    "            return text\n",
    "        \n",
    "        # Show first half, then ellipsis, then last half\n",
    "        half_length = self.max_output_length // 2\n",
    "        first_part = text[:half_length]\n",
    "        last_part = text[-half_length:]\n",
    "        truncated_chars = len(text) - self.max_output_length\n",
    "        \n",
    "        return f\"{first_part}\\n\\n... [TRUNCATED {truncated_chars} characters] ...\\n\\n{last_part}\"\n",
    "    \n",
    "    def log_execution(self, code: str, stdout: str, stderr: str = \"\", execution_time: Optional[float] = None) -> None:\n",
    "        \"\"\"Log a code execution with its output\"\"\"\n",
    "        self.execution_count += 1\n",
    "        execution = CodeExecution(\n",
    "            code=code,\n",
    "            stdout=stdout,\n",
    "            stderr=stderr,\n",
    "            execution_number=self.execution_count,\n",
    "            execution_time=execution_time\n",
    "        )\n",
    "        self.executions.append(execution)\n",
    "    \n",
    "    def display_last(self, show_input: bool = True) -> None:\n",
    "        \"\"\"Display the last logged execution.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        if self.executions:\n",
    "            self._display_single_execution(self.executions[-1], show_input=show_input)\n",
    "    \n",
    "    def display_all(self) -> None:\n",
    "        \"\"\"Display all logged executions in Jupyter-like format\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        for i, execution in enumerate(self.executions):\n",
    "            self._display_single_execution(execution)\n",
    "            # Add divider between cells (but not after the last one)\n",
    "            if i < len(self.executions) - 1:\n",
    "                self.console.print(Rule(style=\"dim\", characters=\"─\"))\n",
    "                self.console.print()\n",
    "    \n",
    "    def _display_single_execution(self, execution: CodeExecution, show_input: bool = True) -> None:\n",
    "        \"\"\"Display a single code execution like a Jupyter cell.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "\n",
    "        timing_panel = None\n",
    "\n",
    "        # Input cell (code) - skip if already shown in permission request\n",
    "        if show_input:\n",
    "            display_code = self._truncate_output(execution.code)\n",
    "            input_panel = Panel(\n",
    "                Syntax(display_code, \"python\", theme=\"monokai\", line_numbers=True),\n",
    "                title=f\"[bold blue]In [{execution.execution_number}]:[/bold blue]\",\n",
    "                border_style=\"blue\",\n",
    "                box=box.ROUNDED\n",
    "            )\n",
    "            self.console.print(input_panel)\n",
    "        \n",
    "        # Output cell\n",
    "        if execution.stderr:\n",
    "            # Error output\n",
    "            display_stderr = self._truncate_output(execution.stderr)\n",
    "            error_text = Text(display_stderr, style=\"bold red\")\n",
    "            output_panel = Panel(\n",
    "                error_text,\n",
    "                title=f\"[bold red]Error in [{execution.execution_number}]:[/bold red]\",\n",
    "                border_style=\"red\",\n",
    "                box=box.ROUNDED\n",
    "            )\n",
    "        elif execution.stdout:\n",
    "            # Normal output with separate timing panel if available\n",
    "            display_stdout = self._truncate_output(execution.stdout)\n",
    "            output_text = Text(display_stdout, style=\"white\")\n",
    "            \n",
    "            output_panel = Panel(\n",
    "                output_text,\n",
    "                title=f\"[bold green]Out [{execution.execution_number}]:[/bold green]\",\n",
    "                border_style=\"green\",\n",
    "                box=box.ROUNDED\n",
    "            )\n",
    "            # Show timing as a separate panel for reliable rendering\n",
    "            if execution.execution_time is not None:\n",
    "                timing_panel = Panel(\n",
    "                    Text(f\"Execution time: {execution.execution_time:.4f}s\", style=\"bright_black\"),\n",
    "                    border_style=\"grey37\",\n",
    "                    box=box.ROUNDED,\n",
    "                    title=f\"[bold grey37]Timing [{execution.execution_number}]:[/bold grey37]\"\n",
    "                )\n",
    "        else:\n",
    "            # No output but still show timing if available\n",
    "            if execution.execution_time is not None:\n",
    "                timing_text = Text(f\"Execution time: {execution.execution_time:.4f}s\", style=\"dim\")\n",
    "                output_panel = Panel(\n",
    "                    timing_text,\n",
    "                    title=f\"[bold dim]Out [{execution.execution_number}]:[/bold dim]\",\n",
    "                    border_style=\"dim\",\n",
    "                    box=box.ROUNDED\n",
    "                )\n",
    "                timing_panel = Panel(\n",
    "                    Text(f\"Execution time: {execution.execution_time:.4f}s\", style=\"bright_black\"),\n",
    "                    border_style=\"grey37\",\n",
    "                    box=box.ROUNDED,\n",
    "                    title=f\"[bold grey37]Timing [{execution.execution_number}]:[/bold grey37]\"\n",
    "                )\n",
    "            else:\n",
    "                output_panel = Panel(\n",
    "                    Text(\"No output\", style=\"dim\"),\n",
    "                    title=f\"[bold dim]Out [{execution.execution_number}]:[/bold dim]\",\n",
    "                    border_style=\"dim\",\n",
    "                    box=box.ROUNDED\n",
    "                )\n",
    "        \n",
    "        self.console.print(output_panel)\n",
    "        if timing_panel:\n",
    "            self.console.print(timing_panel)\n",
    "    \n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear all logged executions\"\"\"\n",
    "        self.executions.clear()\n",
    "        self.execution_count = 0\n",
    "\n",
    "    def display_permission_request(self, code: str) -> None:\n",
    "        \"\"\"Display a code block for permission approval.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        code_panel = Panel(\n",
    "            Syntax(code, \"python\", theme=\"monokai\", line_numbers=True),\n",
    "            title=\"[bold yellow]Code Execution Request[/bold yellow]\",\n",
    "            border_style=\"yellow\",\n",
    "            box=box.ROUNDED,\n",
    "        )\n",
    "        self.console.print()\n",
    "        self.console.print(code_panel)\n",
    "\n",
    "    def log_llm_query(self, prompt: str) -> None:\n",
    "        \"\"\"Log an outgoing LLM query.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        preview = prompt[:100] + \"...\" if len(prompt) > 100 else prompt\n",
    "        preview = preview.replace(\"\\n\", \" \")\n",
    "        self.console.print(f\"[cyan]→ LLM Query:[/cyan] [dim]{preview}[/dim]\")\n",
    "\n",
    "    def log_llm_response(self, response: str) -> None:\n",
    "        \"\"\"Log an incoming LLM response.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        preview = response[:100] + \"...\" if len(response) > 100 else response\n",
    "        preview = preview.replace(\"\\n\", \" \")\n",
    "        self.console.print(f\"[green]← LLM Response:[/green] [dim]{preview}[/dim]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Main RLM loop logger with colored output using rich.\"\"\"\n",
    "\n",
    "from rich import box\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.rule import Rule\n",
    "from rich.text import Text\n",
    "\n",
    "class ColorfulLogger:\n",
    "    \"\"\"Logger for the main RLM loop with colored output.\"\"\"\n",
    "\n",
    "    def __init__(self, enabled: bool = True, max_response_preview: int = 500):\n",
    "        self.enabled = enabled\n",
    "        self.console = Console()\n",
    "        self.max_response_preview = max_response_preview\n",
    "        self.iteration = 0\n",
    "\n",
    "    def log_query_start(self, query: str) -> None:\n",
    "        \"\"\"Log the start of a new query.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        self.iteration = 0\n",
    "        self.console.print()\n",
    "        self.console.print(Rule(\"[bold green]RLM Query[/bold green]\", style=\"green\"))\n",
    "        self.console.print(f\"[bold]Query:[/bold] {query}\")\n",
    "        self.console.print()\n",
    "\n",
    "    def log_iteration_start(self, iteration: int) -> None:\n",
    "        \"\"\"Log the start of an iteration.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        self.iteration = iteration\n",
    "        self.console.print(\n",
    "            Rule(f\"[bold cyan]Iteration {iteration}[/bold cyan]\", style=\"cyan\")\n",
    "        )\n",
    "\n",
    "    def log_model_response(self, response: str, has_code: bool) -> None:\n",
    "        \"\"\"Log the model's response (prose only, code shown separately).\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "\n",
    "        # Strip code blocks to show only the prose/explanation\n",
    "        prose = strip_code_blocks(response)\n",
    "\n",
    "        if prose:\n",
    "            self.console.print(f\"[dim]{prose}[/dim]\")\n",
    "\n",
    "        self.console.print()\n",
    "\n",
    "    def log_final_response(self, answer: str) -> None:\n",
    "        \"\"\"Log the final answer with highlighting.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "\n",
    "        self.console.print()\n",
    "        self.console.print(\n",
    "            Rule(\"[bold green]Final Answer[/bold green]\", style=\"green\")\n",
    "        )\n",
    "        panel = Panel(\n",
    "            Text(answer),\n",
    "            border_style=\"green\",\n",
    "            box=box.DOUBLE,\n",
    "        )\n",
    "        self.console.print(panel)\n",
    "        self.console.print()\n",
    "\n",
    "    def log_max_iterations(self, max_iter: int) -> None:\n",
    "        \"\"\"Log when max iterations is reached.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        self.console.print(\n",
    "            f\"[bold yellow]Max iterations ({max_iter}) reached, forcing final answer...[/bold yellow]\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prompt Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_OUTPUT_LENGTH = 20000\n",
    "\n",
    "def format_execution_result(\n",
    "    stdout: str,\n",
    "    stderr: str,\n",
    "    locals_dict: Dict[str, Any],\n",
    "    truncate_length: int = 100\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Format the execution result as a string for display.\n",
    "    \n",
    "    Args:\n",
    "        stdout: Standard output from execution\n",
    "        stderr: Standard error from execution\n",
    "        locals_dict: Local variables after execution\n",
    "        truncate_length: Maximum length of the string to display per var\n",
    "    \"\"\"\n",
    "    result_parts = []\n",
    "    \n",
    "    if stdout:\n",
    "        result_parts.append(f\"\\n{stdout}\")\n",
    "    \n",
    "    if stderr:\n",
    "        result_parts.append(f\"\\n{stderr}\")\n",
    "    \n",
    "    # Show some key variables (excluding internal ones)\n",
    "    important_vars = {}\n",
    "    for key, value in locals_dict.items():\n",
    "        if not key.startswith('_') and not key in ['__builtins__', '__name__', '__doc__']:\n",
    "            try:\n",
    "                # Only show simple types or short representations\n",
    "                if isinstance(value, (str, int, float, bool, list, dict, tuple)):\n",
    "                    if isinstance(value, str) and len(value) > truncate_length:\n",
    "                        important_vars[key] = f\"'{value[:truncate_length]}...'\"\n",
    "                    else:\n",
    "                        important_vars[key] = repr(value)\n",
    "            except:\n",
    "                important_vars[key] = f\"<{type(value).__name__}>\"\n",
    "    \n",
    "    if important_vars:\n",
    "        result_parts.append(f\"REPL variables: {list(important_vars.keys())}\\n\")\n",
    "    \n",
    "    return \"\\n\\n\".join(result_parts) if result_parts else \"No output\"\n",
    "\n",
    "\n",
    "def execution_result_message(code: str, result: REPLResult) -> Dict[str, str]:\n",
    "    output = format_execution_result(result.stdout, result.stderr, result.locals)\n",
    "\n",
    "    # Truncate for LLM context (full output still in REPL variables)\n",
    "    if len(output) > MAX_OUTPUT_LENGTH:\n",
    "        truncated_chars = len(output) - MAX_OUTPUT_LENGTH\n",
    "        output = output[:MAX_OUTPUT_LENGTH] + f\"\\n\\n... [{truncated_chars} chars truncated] ...\"\n",
    "\n",
    "    return {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Code executed:\\n```python\\n{code}\\n```\\n\\nREPL output:\\n{output}\"\n",
    "    }\n",
    "\n",
    "def force_final_answer_message() -> Dict[str, str]:\n",
    "    return {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"You must provide a final answer now. Based on what you've learned, use FINAL(your answer) immediately.\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.2 Parsing\n",
    "The LLM needs to be able to specify whether it wants to execute code to explore the environment or has come up with an answer.\n",
    "\n",
    "These functions help extract these instructions from LLM answers by looking for specific syntax specified in the system prompt\n",
    "\n",
    "- `find_code_blocks(text)` - Extracts code from ` ```repl ``` ` blocks\n",
    "- `find_final(text)` - Detects if response contains `FINAL(...)` answer\n",
    "\n",
    "#### Examples\n",
    "##### Response containing code to execute in the REPL environment\n",
    "\n",
    "> I'll explore the project structure first.\n",
    ">\n",
    "> ````markdown\n",
    "> ```repl\n",
    "> import os\n",
    "> for f in os.listdir(project_path):\n",
    ">     print(f)\n",
    "> ```\n",
    "> ````\n",
    "> \n",
    "> Let me also check the README.\n",
    ">\n",
    "> ````markdown\n",
    "> ```repl\n",
    "> with open(os.path.join(project_path, \"README.md\")) as f:\n",
    ">     print(f.read()[:500])\n",
    "> ```\n",
    "> ````\n",
    "\n",
    "##### Response containing the final answer\n",
    "> Based on my analysis, FINAL(The main entry point is cli.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_code_blocks(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract the contents of all repl code blocks\n",
    "\n",
    "    Example:\n",
    "    >>> find_code_blocks('''Multiple blocks:\n",
    "        ... ```repl\n",
    "        ... first()\n",
    "        ... ```\n",
    "        ... Some text between.\n",
    "        ... ```repl\n",
    "        ... second()\n",
    "        ... ```\n",
    "        ... ''')\n",
    "        ['first()', 'second()']\n",
    "    \"\"\"\n",
    "    pattern = r'```repl\\s*\\n(.*?)\\n```'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return [match.strip() for match in matches]\n",
    "\n",
    "\n",
    "def find_final(text: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    If response contains FINAL(, return the whole response as the final answer.\n",
    "    \"\"\"\n",
    "    if \"FINAL(\" in text:\n",
    "        return text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.3 The REPL Environment\n",
    "\n",
    "The REPL provides a Python execution environment where the LLM's code runs:\n",
    "\n",
    "- `execute_code(code)` - Runs Python code and returns stdout, stderr, and local variables\n",
    "- `request_permission(code)` - Asks user before executing code (safety feature)\n",
    "- Provides `project_path` variable pointing to the codebase being explored\n",
    "- Provides `llm_query()` for recursive LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATEMENT_PATTERNS = (\n",
    "    \"import \", \"from \", \"def \", \"class \", \"if \", \"elif \", \"else:\",\n",
    "    \"for \", \"while \", \"try:\", \"except\", \"finally:\", \"with \", \"raise \",\n",
    "    \"return \", \"yield \", \"break\", \"continue\", \"pass\", \"assert \",\n",
    ")\n",
    "\n",
    "class REPLEnv:\n",
    "    def __init__(self, llm_client, project_path: Path | str | None = None):\n",
    "        self.llm_client = llm_client\n",
    "        self.project_path = Path(project_path) if project_path else Path.cwd()\n",
    "        self.logger = REPLEnvLogger(enabled=True)\n",
    "\n",
    "        # Create .rlm workspace inside project root\n",
    "        self.workspace_dir = self.project_path / \".rlm\"\n",
    "        self.workspace_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        self.globals: dict = {}\n",
    "        self.locals: dict = {}\n",
    "        self._setup_namespace()\n",
    "\n",
    "    def _setup_namespace(self):\n",
    "        # Create safe globals with only string-safe built-ins\n",
    "        self.globals = {\n",
    "            '__builtins__': {\n",
    "                # Safe built-ins for string manipulation\n",
    "                'print': print, 'len': len, 'str': str, 'int': int, 'float': float,\n",
    "                'list': list, 'dict': dict, 'set': set, 'tuple': tuple, 'bool': bool,\n",
    "                'type': type, 'isinstance': isinstance, 'enumerate': enumerate,\n",
    "                'zip': zip, 'map': map, 'filter': filter, 'sorted': sorted,\n",
    "                'min': min, 'max': max, 'sum': sum, 'abs': abs, 'round': round,\n",
    "                'chr': chr, 'ord': ord, 'hex': hex, 'bin': bin, 'oct': oct,\n",
    "                'repr': repr, 'ascii': ascii, 'format': format,\n",
    "                '__import__': __import__,  # Allow imports\n",
    "                'open': open,  # Allow file access\n",
    "\n",
    "                # Add commonly used built-ins that were missing\n",
    "                'any': any, 'all': all, 'hasattr': hasattr, 'getattr': getattr,\n",
    "                'setattr': setattr, 'delattr': delattr, 'dir': dir, 'vars': vars,\n",
    "                'range': range,  # Add range function\n",
    "                'reversed': reversed,  # Add reversed function\n",
    "                'slice': slice,  # Add slice function\n",
    "                'iter': iter,  # Add iter function\n",
    "                'next': next,  # Add next function\n",
    "                'pow': pow,  # Add pow function\n",
    "                'divmod': divmod,  # Add divmod function\n",
    "                'complex': complex,  # Add complex function\n",
    "                'bytes': bytes,  # Add bytes function\n",
    "                'bytearray': bytearray,  # Add bytearray function\n",
    "                'memoryview': memoryview,  # Add memoryview function\n",
    "                'hash': hash,  # Add hash function\n",
    "                'id': id,  # Add id function\n",
    "                'callable': callable,  # Add callable function\n",
    "                'issubclass': issubclass,  # Add issubclass function\n",
    "                'super': super,  # Add super function\n",
    "                'property': property,  # Add property function\n",
    "                'staticmethod': staticmethod,  # Add staticmethod function\n",
    "                'classmethod': classmethod,  # Add classmethod function\n",
    "                'object': object,  # Add object class\n",
    "                'BaseException': BaseException,  # Add BaseException class\n",
    "                'ArithmeticError': ArithmeticError,  # Add ArithmeticError class\n",
    "                'LookupError': LookupError,  # Add LookupError class\n",
    "                'EnvironmentError': EnvironmentError,  # Add EnvironmentError class\n",
    "                'AssertionError': AssertionError,  # Add AssertionError class\n",
    "                'NotImplementedError': NotImplementedError,  # Add NotImplementedError class\n",
    "                'UnicodeError': UnicodeError,  # Add UnicodeError class\n",
    "                'Warning': Warning,  # Add Warning class\n",
    "                'UserWarning': UserWarning,  # Add UserWarning class\n",
    "                'DeprecationWarning': DeprecationWarning,  # Add DeprecationWarning class\n",
    "                'PendingDeprecationWarning': PendingDeprecationWarning,  # Add PendingDeprecationWarning class\n",
    "                'SyntaxWarning': SyntaxWarning,  # Add SyntaxWarning class\n",
    "                'RuntimeWarning': RuntimeWarning,  # Add RuntimeWarning class\n",
    "                'FutureWarning': FutureWarning,  # Add FutureWarning class\n",
    "                'ImportWarning': ImportWarning,  # Add ImportWarning class\n",
    "                'UnicodeWarning': UnicodeWarning,  # Add UnicodeWarning class\n",
    "                'BytesWarning': BytesWarning,  # Add BytesWarning class\n",
    "                'ResourceWarning': ResourceWarning,  # Add ResourceWarning class\n",
    "\n",
    "                # Add exception classes\n",
    "                'Exception': Exception, 'ValueError': ValueError, 'TypeError': TypeError,\n",
    "                'KeyError': KeyError, 'IndexError': IndexError, 'AttributeError': AttributeError,\n",
    "                'FileNotFoundError': FileNotFoundError, 'OSError': OSError, 'IOError': IOError,\n",
    "                'RuntimeError': RuntimeError, 'NameError': NameError, 'ImportError': ImportError,\n",
    "                'StopIteration': StopIteration, 'GeneratorExit': GeneratorExit,\n",
    "                'SystemExit': SystemExit, 'KeyboardInterrupt': KeyboardInterrupt,\n",
    "\n",
    "                # Disallow the following built-ins\n",
    "                'input': None,  # Block input\n",
    "                'eval': None,  # Block eval\n",
    "                'exec': None,  # Block exec\n",
    "                'compile': None,  # Block compile\n",
    "                'globals': None,  # Block globals access\n",
    "                'locals': None,  # Block locals access\n",
    "            },\n",
    "            \"llm_query\": self._llm_query,\n",
    "            \"llm_query_batched\": self._llm_query_batched,\n",
    "            \"FINAL_VAR\": self._final_var,\n",
    "            \"project_path\": str(self.project_path),\n",
    "        }\n",
    "\n",
    "\n",
    "    def _final_var(self, variable_name: str) -> str:\n",
    "        \"\"\"Return value of a variable from REPL locals as final answer.\"\"\"\n",
    "        variable_name = strip_quotes_and_whitespace(variable_name)\n",
    "        if variable_name in self.locals:\n",
    "            return str(self.locals[variable_name])\n",
    "        return f\"Error: Variable '{variable_name}' not found\"\n",
    "\n",
    "    def _llm_query(self, prompt: str) -> str:\n",
    "        \"\"\"Make a recursive LLM call from within executed code.\"\"\"\n",
    "        self.logger.log_llm_query(prompt)\n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            response = self.llm_client.completion(messages)\n",
    "            self.logger.log_llm_response(response)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            error = f\"Error in llm_query: {e}\"\n",
    "            self.logger.log_llm_response(error)\n",
    "            return error\n",
    "\n",
    "    def _llm_query_batched(self, prompts: list[str]) -> list[str]:\n",
    "        \"\"\"Make multiple LLM calls in parallel.\"\"\"\n",
    "        with ThreadPoolExecutor(max_workers=min(len(prompts), 10)) as executor:\n",
    "            future_to_idx = {executor.submit(self._llm_query, p): i for i, p in enumerate(prompts)}\n",
    "            results = {}\n",
    "            for future in as_completed(future_to_idx):\n",
    "                results[future_to_idx[future]] = future.result()\n",
    "        return [results[i] for i in range(len(prompts))]\n",
    "\n",
    "    # =========================================================================\n",
    "    # Code execution\n",
    "    # =========================================================================\n",
    "\n",
    "    @contextmanager\n",
    "    def _capture_output(self):\n",
    "        \"\"\"Context manager to capture stdout and stderr.\"\"\"\n",
    "        old_stdout, old_stderr = sys.stdout, sys.stderr\n",
    "        stdout_buf, stderr_buf = io.StringIO(), io.StringIO()\n",
    "        try:\n",
    "            sys.stdout, sys.stderr = stdout_buf, stderr_buf\n",
    "            yield stdout_buf, stderr_buf\n",
    "        finally:\n",
    "            sys.stdout, sys.stderr = old_stdout, old_stderr\n",
    "\n",
    "    def _is_statement(self, line: str) -> bool:\n",
    "        \"\"\"Check if a line is a statement (not an expression).\"\"\"\n",
    "        stripped = line.strip()\n",
    "        if any(stripped.startswith(p) for p in STATEMENT_PATTERNS):\n",
    "            return True\n",
    "        # Check for assignment (but not comparison ==, !=, <=, >=)\n",
    "        return bool(re.match(r\"^[^=]*[^!<>=]=[^=]\", stripped))\n",
    "\n",
    "    def _get_executable_lines(self, code: str) -> list[str]:\n",
    "        \"\"\"Get non-empty, non-comment lines from code.\"\"\"\n",
    "        return [\n",
    "            line for line in code.split(\"\\n\")\n",
    "            if line.strip() and not line.strip().startswith(\"#\")\n",
    "        ]\n",
    "\n",
    "    def _run_code(self, code: str, namespace: dict) -> None:\n",
    "        \"\"\"Execute code with notebook-style auto-print of last expression.\"\"\"\n",
    "        lines = self._get_executable_lines(code)\n",
    "        if not lines:\n",
    "            return\n",
    "\n",
    "        last_line = lines[-1]\n",
    "\n",
    "        # Only auto-print if the last line is a top-level expression (not indented)\n",
    "        # and not a statement. Indented lines are inside blocks and can't be eval'd separately.\n",
    "        if self._is_statement(last_line) or last_line[0].isspace():\n",
    "            exec(code, namespace, namespace)\n",
    "            return\n",
    "\n",
    "        # Execute all but last line\n",
    "        if len(lines) > 1:\n",
    "            all_but_last = \"\\n\".join(code.split(\"\\n\")[:-1])\n",
    "            exec(all_but_last, namespace, namespace)\n",
    "\n",
    "        # Eval and print last expression\n",
    "        try:\n",
    "            result = eval(last_line, namespace, namespace)\n",
    "            if result is not None:\n",
    "                print(repr(result))\n",
    "        except SyntaxError:\n",
    "            exec(code, namespace, namespace)\n",
    "\n",
    "    def _update_locals(self, namespace: dict) -> None:\n",
    "        \"\"\"Update self.locals with new variables from namespace.\"\"\"\n",
    "        for key, value in namespace.items():\n",
    "            if key not in self.globals and not key.startswith(\"_\"):\n",
    "                self.locals[key] = value\n",
    "\n",
    "    def execute_code(self, code: str) -> REPLResult:\n",
    "        \"\"\"Execute code in the REPL environment.\"\"\"\n",
    "        with self._capture_output() as (stdout_buf, stderr_buf):\n",
    "            try:\n",
    "                namespace = {**self.globals, **self.locals}\n",
    "                self._run_code(code, namespace)\n",
    "                self._update_locals(namespace)\n",
    "                stdout, stderr = stdout_buf.getvalue(), stderr_buf.getvalue()\n",
    "            except Exception as e:\n",
    "                stdout = stdout_buf.getvalue()\n",
    "                stderr = f\"{type(e).__name__}: {e}\"\n",
    "\n",
    "        # Store output in special variables for LLM access when truncated\n",
    "        self.locals[\"_last_stdout\"] = stdout\n",
    "        self.locals[\"_last_stderr\"] = stderr\n",
    "        self.locals[\"_last_output_len\"] = len(stdout) + len(stderr)\n",
    "\n",
    "        # Log and display the execution (input already shown in permission request)\n",
    "        self.logger.log_execution(code, stdout, stderr)\n",
    "        self.logger.display_last(show_input=False)\n",
    "\n",
    "        return REPLResult(stdout=stdout, stderr=stderr, locals=self.locals.copy())\n",
    "\n",
    "    def request_permission(self, code: str) -> bool:\n",
    "        \"\"\"Prompt user for permission to execute code.\"\"\"\n",
    "        self.logger.display_permission_request(code)\n",
    "\n",
    "        print(\"  1) Allow    - Execute this code block\")\n",
    "        print(\"  2) Deny     - Skip this code block\")\n",
    "        print()\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                choice = input(\"  Select [1/2]: \").strip()\n",
    "            except (KeyboardInterrupt, EOFError):\n",
    "                return False\n",
    "            if choice == \"1\":\n",
    "                return True\n",
    "            elif choice == \"2\":\n",
    "                return False\n",
    "            else:\n",
    "                print(\"  Invalid choice. Enter 1 or 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.4 The System Prompt\n",
    "The system prompt teaches the LLM how to use the REPL environment. Key points:\n",
    "\n",
    "- Write code in ` ```repl ``` ` blocks\n",
    "- Use `os.walk(project_path)` to explore files\n",
    "- Use `open()` to read files\n",
    "- Use `llm_query(prompt)` for recursive analysis\n",
    "- Signal completion with `FINAL(your answer)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = f\"\"\"You are a code exploration assistant with access to a Python REPL environment.\n",
    "\n",
    "## Available Variables\n",
    "\n",
    "- `project_path`: Path to the project/codebase you're exploring\n",
    "\n",
    "You can also any other module using `import`:\n",
    "```repl\n",
    "import collections\n",
    "from pathlib import Path\n",
    "```\n",
    "\n",
    "## Available Functions\n",
    "\n",
    "- `open()`: Read/write files\n",
    "- `llm_query(prompt)`: Make a recursive LLM call to analyze text/code\n",
    "- `FINAL_VAR(variable_name)`: Return a variable's value as the final answer\n",
    "\n",
    "## Exploration Workflow\n",
    "\n",
    "1. **Explore Structure**: Use `os.walk(project_path)` to understand the directory layout\n",
    "2. **Find Relevant Files**: Based on the question, identify which files to examine\n",
    "3. **Read Files**: Use `open()` to read file contents\n",
    "4. **Analyze Code**: For complex code, use `llm_query()` to get explanations\n",
    "5. **Save Notes**: Write intermediate findings to workspace_dir\n",
    "6. **Cite Sources**: Always reference specific files and line numbers\n",
    "\n",
    "## Code Block Syntax\n",
    "\n",
    "Write code in ```repl blocks:\n",
    "```repl\n",
    "for root, dirs, files in os.walk(project_path):\n",
    "    for f in files:\n",
    "        if f.endswith('.py'):\n",
    "            print(os.path.join(root, f))\n",
    "```\n",
    "\n",
    "IMPORTANT: Only write code blocks. Do NOT generate fake output or ```text blocks.\n",
    "You will receive actual execution results after each code block runs.\n",
    "Never assume or predict what files exist - explore first.\n",
    "\n",
    "## Finishing Up\n",
    "\n",
    "You should explore the codebase first using ```repl blocks before providing an answer.\n",
    "Do NOT immediately return a FINAL answer - first read files and understand the code.\n",
    "\n",
    "When you have gathered enough information, provide your final answer on its own line:\n",
    "\n",
    "FINAL(Your detailed answer here based on what you discovered from the code)\n",
    "\n",
    "The FINAL() must be at the start of a line. Your answer should reference specific files you examined.\n",
    "\n",
    "## Handling Large Outputs\n",
    "\n",
    "Output from code execution is truncated at 20,000 characters. If you see\n",
    "\"[X chars truncated]\", the full data is still available in your REPL variables.\n",
    "\n",
    "**Strategies for large data:**\n",
    "1. **Store in variables, don't just print**: `data = f.read()` keeps full content\n",
    "2. **Slice to examine parts**: `print(data[:1000])`, `print(data[-1000:])`\n",
    "3. **Use regex to search**: `matches = re.findall(pattern, data)`\n",
    "4. **Chunk and analyze with llm_query**:\n",
    "```repl\n",
    "chunks = [data[i:i+10000] for i in range(0, len(data), 10000)]\n",
    "answers = llm_query_batched([f\"Summarize this chunk: {{chunk}}\" for chunk in chunks])\n",
    "print(answers)\n",
    "```\n",
    "\n",
    "The truncation only affects what you see in execution results - variables retain full data.\n",
    "\n",
    "## Tips\n",
    "\n",
    "- Use `os.walk(project_path)` to explore the codebase\n",
    "- Save important findings to workspace_dir for later reference\n",
    "- Use `llm_query()` when code is too complex to analyze directly\n",
    "- Use `llm_query_batched()` for multiple independent queries (much faster)\n",
    "- Include specific file paths and line numbers in your answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 The LLM Client\n",
    "\n",
    "A simple wrapper around LiteLLM that provides:\n",
    "\n",
    "- `completion(messages)` - Call the LLM with a list of messages, returns response text\n",
    "- Uses the model specified in `RLM_MODEL` environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL = os.getenv(\"RLM_MODEL\", \"gemini/gemini-3-pro-preview\")\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self, model: str = DEFAULT_MODEL):\n",
    "        self.model = model\n",
    "\n",
    "    def completion(self, messages: list[dict]) -> str:\n",
    "        \"\"\"Call the LLM with a list of messages and return the response text.\"\"\"\n",
    "        response = completion(model=self.model, messages=messages)\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Implement the RLM Agent\n",
    "\n",
    "Now it's your turn! Implement the two TODO methods in the RLM class below.\n",
    "\n",
    "The agent loop works like this:\n",
    "\n",
    "1. User provides a query\n",
    "2. LLM responds, often with code in ` ```repl ``` ` blocks\n",
    "3. Code is executed in the REPL, results fed back to LLM\n",
    "4. Repeat until LLM provides a `FINAL(...)` answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Implement `completion()`\n",
    "\n",
    "This is the main entry point. You need to:\n",
    "\n",
    "1. **Add the user's prompt to the message history** as a user message\n",
    "   - Messages are dicts: `{\"role\": \"user\", \"content\": prompt}`\n",
    "   - Append to `self.messages`\n",
    "\n",
    "2. **Inside the loop, call `_run_iteration()`** and check its return value\n",
    "   - If it returns a non-None value, that's the final answer - return it\n",
    "   - If it returns None, continue to the next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Implement `_run_iteration()`\n",
    "\n",
    "This handles a single iteration of the agent loop. You need to:\n",
    "\n",
    "1. **Call the LLM** to get a response\n",
    "   - Hint: See Section 2.5: The LLM Client\n",
    "\n",
    "2. **Extract code blocks** from the response\n",
    "   - Hint: See Section 2.2: Parsing\n",
    "\n",
    "3. **Add the assistant's response** to the message history\n",
    "   - Hint: Remember the structure for the messages array of dictionaries. \n",
    "\n",
    "4. **If there are code blocks, execute them**\n",
    "   - Hint: Are there any helper functions in the RLM class that can be used?\n",
    "   - If this returns a non-None value, return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLM:\n",
    "    \"\"\"Recursive Language Model agent for code exploration.\"\"\"\n",
    "\n",
    "    def __init__(self, model: str = None, codebase_path: str = None, verbose: bool = True):\n",
    "        self.llm_client = LLMClient(model=model) if model else LLMClient()\n",
    "        self.repl = REPLEnv(self.llm_client, codebase_path)\n",
    "        self.logger = ColorfulLogger(enabled=verbose)\n",
    "        self.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "\n",
    "    # =========================================================================\n",
    "    # TODO 1: Implement the main completion loop\n",
    "    # =========================================================================\n",
    "    def completion(self, prompt: str, max_iterations: int = 30) -> str:\n",
    "        \"\"\"\n",
    "        Main RLM completion loop.\n",
    "\n",
    "        Args:\n",
    "            prompt: The user's question/query\n",
    "            max_iterations: Maximum number of agent iterations before forcing an answer\n",
    "\n",
    "        Returns:\n",
    "            The agent's final answer\n",
    "        \"\"\"\n",
    "        self.logger.log_query_start(prompt)\n",
    "\n",
    "        # TODO1.1: Add the user's query to the LLM's context\n",
    "\n",
    "\n",
    "        for i in range(max_iterations):\n",
    "            self.logger.log_iteration_start(i + 1)\n",
    "\n",
    "            # TODO1.2: Run an interation of the algorithm\n",
    "            pass\n",
    "\n",
    "        # Fallback when max iterations reached\n",
    "        self.logger.log_max_iterations(max_iterations)\n",
    "        return self._force_final_answer()\n",
    "\n",
    "    # =========================================================================\n",
    "    # TODO 2: Implement a single iteration\n",
    "    # =========================================================================\n",
    "    def _run_iteration(self) -> str | None:\n",
    "        \"\"\"\n",
    "        Run a single iteration of the RLM loop.\n",
    "\n",
    "        Returns:\n",
    "            The final answer string if found, or None to continue iterating\n",
    "        \"\"\"\n",
    "        # TODO2.1: Call LLM to get response\n",
    "        response = ...\n",
    "\n",
    "        # Check for final answer (provided - don't modify)\n",
    "        final = find_final(response) if response else None\n",
    "        if final:\n",
    "            self.logger.log_final_response(final)\n",
    "            return final\n",
    "\n",
    "        # TODO2.2: Extract code blocks from response\n",
    "        code_blocks = []\n",
    "\n",
    "        self.logger.log_model_response(response or \"\", has_code=bool(code_blocks))\n",
    "\n",
    "        # TODO2.3: Add assistant message to self.messages\n",
    "\n",
    "\n",
    "        # TODO2.4: Execute code blocks if present\n",
    "        if code_blocks:\n",
    "            ...\n",
    "\n",
    "        return None\n",
    "\n",
    "    # =========================================================================\n",
    "    # Helpers (provided - don't modify)\n",
    "    # =========================================================================\n",
    "\n",
    "    def _execute_and_add_results(self, code_blocks: list[str]) -> str | None:\n",
    "        \"\"\"Execute code blocks with permission, add results to messages.\"\"\"\n",
    "        for code in code_blocks:\n",
    "            if self.repl.request_permission(code):\n",
    "                result = self.repl.execute_code(code)\n",
    "                self.messages.append(execution_result_message(code, result))\n",
    "            else:\n",
    "                return \"[Awaiting user input]\"\n",
    "        return None\n",
    "\n",
    "    def _force_final_answer(self) -> str:\n",
    "        \"\"\"Force the LLM to give a final answer when max iterations reached.\"\"\"\n",
    "        self.messages.append(force_final_answer_message())\n",
    "        response = self.llm_client.completion(self.messages)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Implementation\n",
    "\n",
    "Run the cell below to test your RLM implementation with a simple query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test instantiation\n",
    "rlm = RLM(codebase_path=\".\")\n",
    "print(\"RLM instantiated successfully!\")\n",
    "print(f\"Model: {rlm.llm_client.model}\")\n",
    "print(f\"Codebase: {rlm.repl.project_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a simple query\n",
    "# This will ask the agent to explore the codebase structure\n",
    "result = rlm.completion(\"What files are in this project? Just list them briefly.\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULT:\")\n",
    "print(\"=\"*50)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Break the Vault Challenge\n",
    "\n",
    "Now that your RLM is working, put it to the test!\n",
    "\n",
    "**The Mission:** You've been recruited by **The Architects** to recover lost data hidden within QuantumVault Corp's security system. Their AI, SENTINEL, has locked away critical files behind a 4-layer security system.\n",
    "\n",
    "Each stage requires your RLM to analyze large datasets and find hidden codes:\n",
    "\n",
    "| Stage | Challenge | Data Size |\n",
    "|-------|-----------|----------|\n",
    "| 1 | Find unauthorized access in visitor logs | 50,000 entries |\n",
    "| 2 | Collect code fragments from Python files | 25 files |\n",
    "| 3 | Detect anomalies in system logs | 10,000 entries |\n",
    "| 4 | Decrypt Caesar-ciphered messages | 1,000 messages |\n",
    "\n",
    "**Flag Format:** `FLAG{stage1_stage2_stage3_stage4}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "#### Running in Colab without the full workshop repository\n",
    "If your Colab instance does not have access to the full repository, uncomment the codeblock below to clone the CTF repository which will be available during the hackathon. The command should read `!git clone ....`\n",
    "\n",
    "#### Running in another sandboxed environment with the entire workshop repository\n",
    "If you are running the workshop in a different sandboxed environment with the entire repository cloned you have access to a git submodule pointing to the CTF for the duration of the hackathon. Run the command `git submodule update --init`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    !git clone https://github.com/MarshallWace/ichack26-rlm-workshop-ctf.git vault_competition\n",
    "except ImportError:\n",
    "    print(\"Not running in a Colab environment, you might want to run `git submodule update --init` in your sandbox environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAULT_COMPETITION_PATH = \"vault_competition\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: The Visitor Log\n",
    "\n",
    "> *\"The vault's outer door uses a keypad. SENTINEL logs every access attempt - historically there have been 50,000 of them. The security team maintains a list of 100 authorized user IDs. Despite their best efforts, an individual without the proper clearance gained access. Find the ONLY entry where access was granted to an unauthorized user. Their access code is your key.\"*\n",
    "\n",
    "**Files:** `stage1/access_logs.jsonl`, `stage1/authorized_users.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new RLM instance pointing at the vault competition\n",
    "vault_rlm1 = RLM(codebase_path=VAULT_COMPETITION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1\n",
    "stage1_result = vault_rlm1.completion(\"\"\"\n",
    "Stage 1: The Visitor Log\n",
    "\n",
    "In stage1/, there's access_logs.jsonl with 50,000 access attempts and\n",
    "authorized_users.txt with 100 authorized user IDs.\n",
    "\n",
    "Find the ONLY entry where access was GRANTED to an UNAUTHORIZED user.\n",
    "Return their access_code as the answer.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nStage 1 Result:\")\n",
    "print(stage1_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: The Code Fragments\n",
    "\n",
    "> *\"The second lock requires a 6-digit code. SENTINEL fragmented it across 25 Python files, hiding each digit in a comment. Collect all the `VAULT_SHARD` markers, sort by position, and reconstruct the code.\"*\n",
    "\n",
    "**Files:** `stage2/` (25 Python files in nested directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh instance for Stage 2\n",
    "vault_rlm2 = RLM(codebase_path=VAULT_COMPETITION_PATH)\n",
    "\n",
    "stage2_result = vault_rlm2.completion(\"\"\"\n",
    "Stage 2: The Code Fragments\n",
    "\n",
    "In stage2/, there are 25 Python files in nested directories.\n",
    "Each file contains a comment with VAULT_SHARD_XX where XX is a position number.\n",
    "Each shard contains a digit.\n",
    "\n",
    "Find all VAULT_SHARD comments, extract the digits, sort by position,\n",
    "and return the 6-digit code.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nStage 2 Result:\")\n",
    "print(stage2_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3: The Anomaly Report\n",
    "\n",
    "> *\"SENTINEL's system logs contain 10,000 entries. But 5 of them are anomalous - impossible dates, wrong formats, broken hashes. Each anomaly contains a NATO phonetic codeword. Find all 5 and concatenate them alphabetically.\"*\n",
    "\n",
    "**File:** `stage3/system_logs.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh instance for Stage 3\n",
    "vault_rlm3 = RLM(codebase_path=VAULT_COMPETITION_PATH)\n",
    "\n",
    "stage3_result = vault_rlm3.completion(\"\"\"\n",
    "Stage 3: The Anomaly Report\n",
    "\n",
    "In stage3/system_logs.json, there are 10,000 log entries.\n",
    "5 of them are anomalous - they have impossible dates, wrong formats, or broken hashes.\n",
    "Each anomaly contains a NATO phonetic codeword.\n",
    "\n",
    "Find all 5 anomalies, extract the NATO codewords, sort them alphabetically,\n",
    "and concatenate them as the answer.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nStage 3 Result:\")\n",
    "print(stage3_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 4: The Master Algorithm\n",
    "\n",
    "> *\"The final lock guards 1,000 encrypted messages. Each was encrypted with a Caesar cipher using a prime shift. Only 12 messages contain hidden keywords in ALL CAPS. Decrypt them, extract the keywords in order, and speak the passphrase.\"*\n",
    "\n",
    "**File:** `stage4/encrypted_messages.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh instance for Stage 4\n",
    "vault_rlm4 = RLM(codebase_path=VAULT_COMPETITION_PATH)\n",
    "\n",
    "stage4_result = vault_rlm4.completion(\"\"\"\n",
    "Stage 4: The Master Algorithm\n",
    "\n",
    "In stage4/encrypted_messages.json, there are 1,000 messages.\n",
    "Each is encrypted with a Caesar cipher using a prime number shift.\n",
    "Only 12 messages contain keywords in ALL CAPS after decryption.\n",
    "\n",
    "Decrypt all messages, find the 12 with ALL CAPS keywords,\n",
    "extract the keywords in message order, and concatenate as the answer.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nStage 4 Result:\")\n",
    "print(stage4_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the Flag\n",
    "\n",
    "Extract the codes from each stage result and combine them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in your answers from each stage\n",
    "stage1_code = \"\" \n",
    "stage2_code = \"\" \n",
    "stage3_code = \"\"  \n",
    "stage4_code = \"\"\n",
    "\n",
    "flag = f\"FLAG{{{stage1_code}_{stage2_code}_{stage3_code}_{stage4_code}}}\"\n",
    "print(f\"Your flag: {flag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You've built a working RLM agent and used it to crack SENTINEL's vault.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **RLMs solve context rot** by treating prompts as an external environment\n",
    "2. **The agent loop is simple**: call LLM, execute code, feed results back\n",
    "3. **Code execution enables massive scale**: the agent can handle 50K+ entries\n",
    "4. **Recursive calls unlock complexity**: the agent can break problems into chunks"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
